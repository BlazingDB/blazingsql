{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blazingsql import BlazingContext\n",
    "from blazingsql import DataType, S3EncryptionType\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import tpchQueries as tpch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drill = \"drill\"\n",
    "spark = \"spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_prefix = os.getenv(\"CONDA_PREFIX\")\n",
    "\n",
    "bucket_name = os.getenv(\"BLAZINGSQL_E2E_AWS_S3_BUCKET_NAME\")\n",
    "access_key_id = os.getenv(\"BLAZINGSQL_E2E_AWS_S3_ACCESS_KEY_ID\")\n",
    "secret_key = os.getenv(\"BLAZINGSQL_E2E_AWS_S3_SECRET_KEY\")\n",
    "\n",
    "gs_project_id=os.getenv(\"BLAZINGSQL_E2E_GS_PROJECT_ID\")\n",
    "gs_bucket_name=os.getenv(\"BLAZINGSQL_E2E_GS_BUCKET_NAME\")\n",
    "\n",
    "execution_mode=os.getenv(\"BLAZINGSQL_E2E_EXECUTION_MODE\")\n",
    "ip_scheduler=os.getenv(\"BLAZINGSQL_E2E_IP_SCHEDULER\")\n",
    "\n",
    "file_results_dir = conda_prefix + \"/blazingsql-testing-files/results/\" \n",
    "data_dir = conda_prefix + \"/blazingsql-testing-files/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def git_clone():\n",
    "    import git\n",
    "    git.Git(\"$CONDA_PREFIX\").clone(\"https://github.com/rapidsai/blazingsql-testing-files.git\")\n",
    "    \n",
    "def git_pull():\n",
    "    import git\n",
    "    os.chdir(conda_prefix + \"/blazingsql-testing-files\")\n",
    "\n",
    "def unzip():\n",
    "\n",
    "    import tarfile\n",
    "    \n",
    "    os.chdir(conda_prefix + \"/blazingsql-testing-files/\")\n",
    "    tar = tarfile.open('data.tar.gz', \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(bc, engine, query, queryId, queryType, worder, orderBy,  acceptable_difference, use_percentage, input_type, **kwargs):\n",
    "    \n",
    "    result_gdf = bc.sql(query)       \n",
    "\n",
    "    filename = str(\"TPCH\").upper() + \"-\" + str(queryId) + \".parquet\"\n",
    "\n",
    "    result_file = file_results_dir + \"/\" + str(engine) + \"/\" + filename\n",
    "    \n",
    "    pdf2 = pd.read_parquet(result_file)\n",
    "\n",
    "    stringResult = \"\" \n",
    "    \n",
    "    if result_gdf is not None:\n",
    "        if result_gdf.columns is not None:\n",
    "            import dask_cudf\n",
    "            \n",
    "            if type(result_gdf) is dask_cudf.core.DataFrame:\n",
    "                result_gdf = result_gdf.compute()\n",
    "            \n",
    "            expected_dtypes = result_gdf.dtypes.to_list()\n",
    "            \n",
    "            pdf = upcast_to_float(result_gdf).fillna(get_null_constants(result_gdf)).to_pandas()\n",
    "            \n",
    "            if worder == 1 and pdf.size != 0:\n",
    "                pdf.sort_values([orderBy] if orderBy else pdf.columns.to_list(), inplace = True)\n",
    "\n",
    "            stringResult = print_query_results(pdf, pdf2,  acceptable_difference, use_percentage, engine)\n",
    "\n",
    "    return stringResult\n",
    "          \n",
    "\n",
    "def print_query_results(pdf1, pdf2,  acceptable_difference, use_percentage, engine):\n",
    "\n",
    "    columnNamesComparison = compare_column_names(pdf1, pdf2)\n",
    "    if columnNamesComparison != True:\n",
    "        error_message = \"Column names are not the same\"\n",
    "    \n",
    "    resultComparisson = compare_results(pdf1, pdf2,  acceptable_difference, use_percentage, engine)\n",
    "    if resultComparisson != \"Success\":\n",
    "        error_message = resultComparisson[6:]\n",
    "\n",
    "    stringResult = resultComparisson\n",
    "    if resultComparisson != \"Success\" or columnNamesComparison == False:\n",
    "        stringResult = \"Fail\"    \n",
    "        \n",
    "    return stringResult\n",
    "\n",
    "def compare_column_names(pdf1, pdf2):\n",
    "    if len(pdf1.columns) != len(pdf2.columns):\n",
    "        if pdf1.values.size == 0 and pdf2.values.size == 0:\n",
    "            return True\n",
    "        print(\"Different set of columns\")\n",
    "        return False\n",
    "    for blzCol, drillCol in zip(pdf1.columns.values.tolist(), pdf2.columns.values.tolist()):\n",
    "        if blzCol != drillCol:\n",
    "            if begins_with(drillCol, blzCol, \"EXPR\")==False and begins_with(drillCol, blzCol, \"count(\")==False:\n",
    "                print(\"Different columns\")\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def begins_with(col1, col2, exp):\n",
    "    return col1.startswith(exp) or col2.startswith(exp) \n",
    "\n",
    "def compare_results(vdf1, vdf2,  acceptable_difference, use_percentage, engine):\n",
    "    if vdf1.size == 0 and vdf2.size == 0:\n",
    "        return 'Success'\n",
    "    elif pre_compare_results(vdf1.values, vdf2.values):\n",
    "        return 'Success'\n",
    "    else:\n",
    "        res = assert_equal(vdf1, vdf2, acceptable_difference, use_percentage, engine) \n",
    "        return res\n",
    "    \n",
    "def upcast_to_float(df):\n",
    "    for name in df.columns:\n",
    "        if np.issubdtype(df[name].dtype, np.bool_):\n",
    "            df[name] = df[name].astype(np.float32)\n",
    "        elif np.issubdtype(df[name].dtype, np.integer):\n",
    "            df[name] = df[name].astype(np.float64)\n",
    "    return df\n",
    "\n",
    "def get_null_constants(df):\n",
    "    null_values = {}\n",
    "    for col, dtype in df.dtypes.to_dict().items():\n",
    "        if np.issubdtype(dtype, np.datetime64):\n",
    "            null_values[col] = np.datetime64('nat')\n",
    "        elif np.issubdtype(dtype, np.number):\n",
    "            null_values[col] = np.nan\n",
    "    return null_values\n",
    "\n",
    "def pre_compare_results(vdf1, vdf2):\n",
    "    try:\n",
    "        np.testing.assert_equal(vdf1, vdf2)\n",
    "        return True\n",
    "    except (AssertionError, ValueError, TypeError) as e:\n",
    "        return False\n",
    "    \n",
    "def assert_equal(pdf1, pdf2, acceptable_difference, use_percentage, engine):\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "    if pdf1.shape[0] == pdf2.shape[0]:\n",
    "        if pdf1.shape[1] == pdf2.shape[1]:\n",
    "\n",
    "            pdf1.reset_index(drop=True, inplace=True)\n",
    "            pdf2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            exac_comp = pdf1.select_dtypes(exclude=np.inexact).equals(pdf2.select_dtypes(exclude=np.inexact))\n",
    "\n",
    "            tmp_pdf1 = pdf1.select_dtypes(include=np.inexact)\n",
    "            tmp_pdf2 = pdf2.select_dtypes(include=np.inexact)\n",
    "            \n",
    "            res = np.all(exac_comp) and np.allclose(tmp_pdf1.values, tmp_pdf2.values, acceptable_difference, equal_nan=True)\n",
    "            if res:\n",
    "                return  'Success'\n",
    "            else:\n",
    "                return  'Fail: Different values'\n",
    "        else:\n",
    "            return  'Fail: Different number of columns blzSQLresult: ' + str(pdf1.shape[1]) + ' ' + (engine) + ' result: ' + str(pdf2.shape[1])\n",
    "    else:\n",
    "        return  'Fail: Different number of rows blzSQLresult: ' + str(pdf1.shape[0]) + ' ' + (engine) + ' result: '+ str(pdf2.shape[0])\n",
    "\n",
    "def create_tables(bc, dir_data_lc, fileSchemaType, **kwargs):\n",
    "    \n",
    "    ext = \"parquet\" \n",
    "    \n",
    "    tpchTables = ['customer','orders','supplier','lineitem','part','partsupp','nation','region']\n",
    "\n",
    "    tables = kwargs.get('tables', tpchTables)\n",
    "\n",
    "    dir_data_lc = dir_data_lc + \"tpch/\"\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        table_files = (\"%s/%s_[0-9]*.%s\") % (dir_data_lc, table, ext)\n",
    "        t = None\n",
    "        t = bc.create_table(table, table_files)\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    install(\"gitpython\")\n",
    "    \n",
    "    if not os.path.exists(conda_prefix + \"/blazingsql-testing-files/\"):\n",
    "        git_clone()\n",
    "    else:\n",
    "        git_pull()\n",
    "    \n",
    "    unzip()\n",
    "    \n",
    "    queryType = ' Local Tests ' \n",
    "\n",
    "    if execution_mode == \"1\":\n",
    "        print(\"Executing test in Single Node\")\n",
    "        bc = BlazingContext()\n",
    "    else:\n",
    "        print(\"Executing test in Distributed Mode\")\n",
    "        from dask.distributed import Client\n",
    "        port = '8786'\n",
    "        scheduler = ip_scheduler + ':' + port\n",
    "        client = Client(scheduler)\n",
    "        print(\"Dask client ready!\")\n",
    "        bc = BlazingContext(dask_client = client, network_interface='lo')                 \n",
    "\n",
    "    log_dict = {}\n",
    "    \n",
    "    def executionLocalTest(queryType): \n",
    "        \n",
    "        #Read Data TPCH------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        tables = ['nation', 'region', 'supplier','customer','lineitem','orders', 'part', 'partsupp']\n",
    "        \n",
    "        data_types =  [DataType.PARQUET] # TODO json\n",
    "    \n",
    "        for fileSchemaType in data_types:\n",
    "            create_tables(bc, data_dir, fileSchemaType, tables=tables)\n",
    "\n",
    "        #   Run Query -----------------------------------------------------------------------------\n",
    "            worder = 1 # Parameter to indicate if its necessary to order the resulsets before compare them\n",
    "            use_percentage = False\n",
    "            acceptable_difference = 0.01\n",
    "                     \n",
    "            print('==============================')\n",
    "            print(queryType)\n",
    "            print('==============================')\n",
    "        \n",
    "            queryId = 'TEST_01'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)           \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "            \n",
    "            queryId = 'TEST_02'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)            \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_03'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_04'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            queryId = 'TEST_05'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)           \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_06'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_07'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)            \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "    executionLocalTest(queryType)\n",
    "    \n",
    "    queryType = ' S3 Tests ' \n",
    "    \n",
    "    def executionS3Test(queryType): \n",
    "        \n",
    "        #Read Data TPCH------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        authority = \"tpch_s3\"\n",
    "        \n",
    "        bc.s3(authority, bucket_name=bucket_name, encryption_type=S3EncryptionType.NONE,\n",
    "              access_key_id=access_key_id, secret_key=secret_key)\n",
    "\n",
    "        dir_data_lc = \"s3://\" + authority + \"/\" + \"DataSet100Mb2part/\" \n",
    "        \n",
    "        tables = ['nation', 'region', 'supplier','customer','lineitem','orders', 'part', 'partsupp']\n",
    "        data_types =  [DataType.PARQUET] # TODO json\n",
    "    \n",
    "        for fileSchemaType in data_types:\n",
    "            create_tables(bc, data_dir, fileSchemaType, tables=tables)\n",
    "\n",
    "        #   Run Query -----------------------------------------------------------------------------\n",
    "            worder = 1 # Parameter to indicate if its necessary to order the resulsets before compare them\n",
    "            use_percentage = False\n",
    "            acceptable_difference = 0.01\n",
    "                     \n",
    "            print('==============================')\n",
    "            print(queryType)\n",
    "            print('==============================')\n",
    "        \n",
    "            queryId = 'TEST_08'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)    \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_09'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            queryId = 'TEST_10'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)          \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_11'\n",
    "            #print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)          \n",
    "            #result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            queryId = 'TEST_12'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)          \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_13'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)        \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_14'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "\n",
    "            log_dict[queryId] = result\n",
    "\n",
    "    executionS3Test(queryType)\n",
    "    \n",
    "    queryType = ' GS Tests ' \n",
    "    \n",
    "    def executionGSTest(queryType): \n",
    "        \n",
    "        authority = \"tpch_gs\"\n",
    "        \n",
    "        bc.gs(authority,\n",
    "        project_id=gs_project_id,\n",
    "        bucket_name=gs_bucket_name,\n",
    "        use_default_adc_json_file=True,\n",
    "        adc_json_file='')\n",
    "        \n",
    "        dir_data_lc = 'gcs://'+ authority +'/100MB2Part/'\n",
    "        \n",
    "        tables = ['nation', 'region', 'supplier','customer','lineitem','orders', 'part', 'partsupp']\n",
    "        data_types =  [DataType.PARQUET] \n",
    "    \n",
    "        for fileSchemaType in data_types:\n",
    "            create_tables(bc, data_dir, fileSchemaType, tables=tables)\n",
    "\n",
    "        #   Run Query -----------------------------------------------------------------------------\n",
    "            worder = 1 # Parameter to indicate if its necessary to order the resulsets before compare them\n",
    "            use_percentage = False\n",
    "            acceptable_difference = 0.01\n",
    "                     \n",
    "            print('==============================')\n",
    "            print(queryType)\n",
    "            print('==============================')\n",
    "        \n",
    "            queryId = 'TEST_15'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)       \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_16'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)        \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            queryId = 'TEST_17'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)     \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_18'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_19'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)         \n",
    "            result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_20'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)            \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_21'\n",
    "            print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)      \n",
    "            result = run_query(bc, spark, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "            \n",
    "            log_dict[queryId] = result\n",
    "\n",
    "            queryId = 'TEST_22'\n",
    "            #print(\"Executing \" + queryId + \" ... \")\n",
    "            query = tpch.get_tpch_query(queryId)       \n",
    "            #result = run_query(bc, drill, query, queryId, queryType, worder, '', acceptable_difference, use_percentage, fileSchemaType)\n",
    "    \n",
    "    executionGSTest(queryType)\n",
    "\n",
    "    green = bcolors.OKGREEN\n",
    "    endc = bcolors.ENDC\n",
    "\n",
    "    print(green + \"=======================================\")\n",
    "    print(\"SUMMARY TESTS\")\n",
    "    print(\"=======================================\" + endc)\n",
    "\n",
    "    for key, value in log_dict.items():\n",
    "\t    print('\"{}\" : {} '.format(key, value))\n",
    "\n",
    "    print (green + \"=======================================\" + endc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing test in Single Node\n",
      "BlazingContext ready\n",
      "==============================\n",
      " Local Tests \n",
      "==============================\n",
      "Executing TEST_01 ... \n",
      "Executing TEST_02 ... \n",
      "Executing TEST_03 ... \n",
      "Executing TEST_05 ... \n",
      "Executing TEST_06 ... \n",
      "Executing TEST_07 ... \n",
      "tpch_s3\n",
      "blazingsql-bucket\n",
      "S3EncryptionType.NONE\n",
      "AKIAJGB3SR3IXU3TE5WA\n",
      "FeSNGCJ6xHZJ2MeQjXJ4JXyxmwM9fEvGXHPv/xVu\n",
      "==============================\n",
      " S3 Tests \n",
      "==============================\n",
      "Executing TEST_08 ... \n",
      "Executing TEST_10 ... \n",
      "Executing TEST_12 ... \n",
      "Executing TEST_13 ... \n",
      "Executing TEST_14 ... \n",
      "Couldn't create gcs::ClientOptions for Project ID blazingdb-jenkins status=Could not automatically determine credentials. For more information, please see https://developers.google.com/identity/protocols/application-default-credentials\n",
      "==============================\n",
      " GS Tests \n",
      "==============================\n",
      "Executing TEST_15 ... \n",
      "Executing TEST_17 ... \n",
      "Executing TEST_18 ... \n",
      "Executing TEST_19 ... \n",
      "Executing TEST_20 ... \n",
      "Executing TEST_21 ... \n",
      "\u001b[92m=======================================\n",
      "SUMMARY TESTS\n",
      "=======================================\u001b[0m\n",
      "\"TEST_01\" : Success \n",
      "\"TEST_02\" : Fail \n",
      "\"TEST_03\" : Fail \n",
      "\"TEST_05\" : Success \n",
      "\"TEST_06\" : Success \n",
      "\"TEST_07\" : Success \n",
      "\"TEST_08\" : Success \n",
      "\"TEST_10\" : Fail \n",
      "\"TEST_12\" : Success \n",
      "\"TEST_13\" : Fail \n",
      "\"TEST_14\" : Success \n",
      "\"TEST_15\" : Success \n",
      "\"TEST_17\" : Success \n",
      "\"TEST_18\" : Success \n",
      "\"TEST_19\" : Success \n",
      "\"TEST_20\" : Success \n",
      "\"TEST_21\" : Fail \n",
      "\u001b[92m=======================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rapids Stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
